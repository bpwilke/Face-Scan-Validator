{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Scan Validator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project is to explore the use of a \"siamese\" deep neural network to compare two embeddings created from images. The goal is to create an application that will allow for the realtime image of a face to be compared to a database of facial images as a security validator (i.e. a building entrance checkpoint).\n",
    "\n",
    "The project will utilize transfer learning to initialize a pre-trained Resnet CNN to produce the embeddings for comparison. Comparison will be made using Euclidean distance function to understand, which embeddings are most simlar. If no embeddings are close (set with a threshold) - than it's assumed the new image isn't in the database and entrance is not granted. \n",
    "\n",
    "This will also be my first project exploring OpenCV.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Required Modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/bwilke/Library/Mobile Documents/com~apple~CloudDocs/DataScience@SMU/Data-Science-Portfolio/Face-Scan-Validator'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/bwilke/Library/Mobile Documents/com~apple~CloudDocs/DataScience@SMU/Data-Science-Portfolio/Face-Scan-Validator/Raw-Images\n"
     ]
    }
   ],
   "source": [
    "%cd Raw-Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.DS_Store']\n",
      "['opencv_frame_4.png', 'opencv_frame_2.png', 'opencv_frame_3.png', 'opencv_frame_1.png', 'opencv_frame_0.png']\n",
      "['opencv_frame_4.png', 'opencv_frame_2.png', 'opencv_frame_3.png', 'opencv_frame_1.png', 'opencv_frame_0.png']\n"
     ]
    }
   ],
   "source": [
    "rootdir = '/Users/bwilke/Library/Mobile Documents/com~apple~CloudDocs/DataScience@SMU/Data-Science-Portfolio/Face-Scan-Validator/Raw-Images'\n",
    "for subdir, dirs, files in os.walk(rootdir):\n",
    "    print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opencv_frame_0.png written!\n",
      "opencv_frame_1.png written!\n",
      "opencv_frame_2.png written!\n",
      "opencv_frame_3.png written!\n",
      "opencv_frame_4.png written!\n",
      "Escape hit, closing...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "camera = cv2.VideoCapture(2)\n",
    "\n",
    "img_counter = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = camera.read()\n",
    "    if not ret:\n",
    "        print(\"failed to grab frame\")\n",
    "        break\n",
    "    cv2.imshow(\"test\", frame)\n",
    "\n",
    "    k = cv2.waitKey(1)\n",
    "    if k%256 == 27:\n",
    "        # ESC pressed\n",
    "        print(\"Escape hit, closing...\")\n",
    "        break\n",
    "    elif k%256 == 32:\n",
    "        # SPACE pressed\n",
    "        img_name = \"opencv_frame_{}.png\".format(img_counter)\n",
    "        cv2.imwrite(img_name, frame)\n",
    "        print(\"{} written!\".format(img_name))\n",
    "        img_counter += 1\n",
    "\n",
    "camera.release()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://machinelearningmastery.com/how-to-use-transfer-learning-when-developing-convolutional-neural-network-models/\n",
    "# https://keras.io/api/applications/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load ResNet 50 architecture and pre-trained (ImageNet) weights\n",
    "model = ResNet50()\n",
    "# pop off the final fully connected layer as we want the (1,2048) output embedding prior\n",
    "model = Model(inputs = model.inputs, outputs = model.layers[-2].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that takes our model and an image filename, returns embedding of shape (1, 2048)\n",
    "def image_to_embedding(model, image):\n",
    "    # load image, convert to numpy array\n",
    "    np_image = img_to_array(load_img(image, target_size=(224, 224)))\n",
    "    # preprocess for Resnet 50\n",
    "    np_image = preprocess_input(np_image)\n",
    "    # create a \"batch\" of 1 for valid input to ResNet input layer\n",
    "    np_image = np_image.reshape(1, 224, 224, 3)\n",
    "    # return embedding\n",
    "    return model.predict(np_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that takes 2 of our embeddings and computes their Euclidean Distance\n",
    "def embedding_distance(a, b):\n",
    "    pass\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
